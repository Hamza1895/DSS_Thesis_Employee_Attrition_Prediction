{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IS_9KidQ0klq"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn numpy pandas imbalanced-learn optuna --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zieMRdKnQnXf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"datasets/IBM Dataset 1.csv\")\n",
    "\n",
    "data = data.drop(columns=['EmployeeCount', 'EmployeeNumber', 'StandardHours', 'Over18'], errors='ignore')\n",
    "\n",
    "engineered_features = [\n",
    "    ('IncomePerJobLevel', lambda df: df['MonthlyIncome'] / (df['JobLevel'] + 1)),\n",
    "    ('TotalWorkingYearsToJobLevelRatio', lambda df: df['TotalWorkingYears'] / (df['JobLevel'] + 1)),\n",
    "    ('YearsAtCompanyToAgeRatio', lambda df: df['YearsAtCompany'] / (df['Age'] + 1)),\n",
    "    ('YearsAtCompanyToYearsInCurrentRoleRatio', lambda df: df['YearsAtCompany'] / (df['YearsInCurrentRole'] + 1))\n",
    "]\n",
    "\n",
    "for name, func in engineered_features:\n",
    "    data[name] = func(data)\n",
    "\n",
    "numerical_columns = [x for x in data.select_dtypes(include=['int64', 'float64']).columns if x!= \"Attrition\"]\n",
    "\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "processed_data = data.copy()\n",
    "\n",
    "nominal_columns = [ 'Department', 'EducationField', 'JobRole', 'MaritalStatus']\n",
    "processed_data = pd.get_dummies(processed_data, columns=nominal_columns, drop_first=True)\n",
    "\n",
    "processed_data['Attrition'] = processed_data['Attrition'].map({'No': 0, 'Yes': 1})\n",
    "processed_data['OverTime'] = processed_data['OverTime'].map({'No': 0, 'Yes': 1})\n",
    "processed_data['Gender'] = processed_data['Gender'].map({'Male': 0, 'Female': 1})\n",
    "processed_data['BusinessTravel'] = processed_data['BusinessTravel'].map({'Non-Travel': 0, 'Travel_Rarely': 1, 'Travel_Frequently': 2})\n",
    "\n",
    "X_processed = processed_data.drop(columns=[\"Attrition\"], errors='ignore')\n",
    "y_processed = processed_data[\"Attrition\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "moDniTdYsnC2",
    "outputId": "8282e911-0d6f-46ec-920c-45ab799a10e6"
   },
   "outputs": [],
   "source": [
    "N_TRIALS = 50\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from optuna.importance import get_param_importances\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_processed, test_size=0.2, random_state=42, stratify=y_processed)\n",
    "\n",
    "sampling_techniques = {\n",
    "    \"None\": None,\n",
    "    \"SMOTE\": SMOTE(random_state=42),\n",
    "    \"BorderlineSMOTE\": BorderlineSMOTE(random_state=42),\n",
    "    \"SMOTETomek\": SMOTETomek(random_state=42),\n",
    "    \"ADASYN\": ADASYN(random_state=42),\n",
    "}\n",
    "\n",
    "models_and_params = {\n",
    "    \"MLP1\": MLPClassifier,\n",
    "    \"MLP2\": MLPClassifier,\n",
    "    \"MLP3\": MLPClassifier,\n",
    "    \"MLP4\": MLPClassifier,\n",
    "   \n",
    "}\n",
    "\n",
    "combined_results = []\n",
    "\n",
    "for sampling_name, sampler_type in sampling_techniques.items():\n",
    "    for model_name, model_class in models_and_params.items():\n",
    "        print(f\"Optimizing {model_name}\")\n",
    "\n",
    "        def objective(trial, sampler):\n",
    "            \n",
    "            if model_name == \"MLP1\":\n",
    "                model = MLPClassifier(\n",
    "                    hidden_layer_sizes=trial.suggest_categorical('hidden_layer_sizes', [(128, 64, 32, 16)]),\n",
    "                    activation=trial.suggest_categorical(\"activation\", [\"tanh\", \"relu\"]),\n",
    "                    solver=trial.suggest_categorical(\"solver\", [\"adam\"]),\n",
    "                    alpha=trial.suggest_float(\"alpha\", 1e-5, 1e-2, log=True),\n",
    "                    learning_rate_init=trial.suggest_float(\"learning_rate_init\", 1e-4, 1e-1, log=True),\n",
    "                    max_iter=1500,\n",
    "                    random_state=42)\n",
    "\n",
    "            elif model_name == \"MLP2\":\n",
    "                model = MLPClassifier(\n",
    "                    hidden_layer_sizes=trial.suggest_categorical('hidden_layer_sizes', [(256, 128, 64, 32, 16), (64, 32, 16), (32, 16)]),\n",
    "                    activation=trial.suggest_categorical(\"activation\", [\"tanh\", \"relu\"]),\n",
    "                    solver=trial.suggest_categorical(\"solver\", [\"adam\"]),\n",
    "                    alpha=trial.suggest_float(\"alpha\", 1e-5, 1e-2, log=True),\n",
    "                    learning_rate_init=trial.suggest_float(\"learning_rate_init\", 1e-4, 1e-1, log=True),\n",
    "                    max_iter=1500,\n",
    "                    random_state=42)\n",
    "\n",
    "            elif model_name == \"MLP3\":\n",
    "                model = MLPClassifier(\n",
    "                    hidden_layer_sizes=trial.suggest_categorical('hidden_layer_sizes', [( 64,64, 64), (64, 64)]),\n",
    "                    activation=trial.suggest_categorical(\"activation\", [\"tanh\", \"relu\"]),\n",
    "                    solver=trial.suggest_categorical(\"solver\", [\"adam\"]),\n",
    "                    alpha=trial.suggest_float(\"alpha\", 1e-5, 1e-2, log=True),\n",
    "                    learning_rate_init=trial.suggest_float(\"learning_rate_init\", 1e-4, 1e-1, log=True),\n",
    "                    max_iter=1500,\n",
    "                    random_state=42)\n",
    "\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown model: {model_name}\")\n",
    "\n",
    "\n",
    "            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            f1_scores = []\n",
    "\n",
    "            for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "                X_train_cv, X_val_cv = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_train_cv, y_val_cv = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "                preprocessor = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('num', numeric_transformer, numerical_columns)],\n",
    "                    remainder='passthrough')\n",
    "\n",
    "                if sampler:\n",
    "\n",
    "                    X_train_cv, y_train_cv = sampler.fit_resample(X_train_cv, y_train_cv)\n",
    "                    X_train_cv = preprocessor.fit_transform(X_train_cv)\n",
    "                else:\n",
    "                    X_train_cv = preprocessor.fit_transform(X_train_cv)\n",
    "                \n",
    "                X_val_cv = preprocessor.transform(X_val_cv)\n",
    "\n",
    "                model.fit(X_train_cv, y_train_cv)\n",
    "                y_pred_cv = model.predict(X_val_cv)\n",
    "\n",
    "                f1 = f1_score(y_val_cv, y_pred_cv, average=\"weighted\")\n",
    "                f1_scores.append(f1)\n",
    "\n",
    "                trial.report(f1, fold)\n",
    "\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "            return np.mean(f1_scores)\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(lambda trial: objective(trial, sampler_type), n_trials=N_TRIALS)\n",
    "\n",
    "\n",
    "        try:\n",
    "            importance = get_param_importances(study)\n",
    "        except:\n",
    "            importance = None\n",
    "\n",
    "        best_trial = study.best_trial\n",
    "        best_params = best_trial.params\n",
    "\n",
    "        model_params = best_params.copy()\n",
    "        if model_name in [\"KNN\", \"Gaussian Naive Bayes\"]:\n",
    "            best_model = model_class(**model_params)\n",
    "        else:\n",
    "            best_model = model_class(**model_params, random_state=42)\n",
    "\n",
    "        preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numerical_columns)],remainder='passthrough')\n",
    "        if sampler_type:\n",
    "            X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "            X_train_resampled, y_train_resampled = sampler_type.fit_resample(X_train_transformed, y_train)\n",
    "        else:\n",
    "            X_train_resampled = preprocessor.fit_transform(X_train)\n",
    "            y_train_resampled = y_train\n",
    "\n",
    "\n",
    "        best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "        y_pred_test = best_model.predict(X_test_transformed)\n",
    "        y_prob_test = best_model.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "        f1_weighted = f1_score(y_test, y_pred_test, average=\"weighted\")\n",
    "        precision_weighted = precision_score(y_test, y_pred_test, average=\"weighted\")\n",
    "        recall_weighted = recall_score(y_test, y_pred_test, average=\"weighted\")\n",
    "\n",
    "        roc_auc = roc_auc_score(y_test, y_prob_test)\n",
    "\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "     \n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_prob_test)\n",
    "        pr_auc = auc(recall, precision)\n",
    "\n",
    "        combined_results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Sampling\": sampling_name,\n",
    "            \"Validation F1-Score (CV)\": best_trial.value,\n",
    "            \"Test F1-Score (Weighted)\": f1_weighted,\n",
    "            \"Test Precision (Weighted)\": precision_weighted,\n",
    "            \"Test Recall (Weighted)\": recall_weighted,\n",
    "            \"Test ROC-AUC\": roc_auc,\n",
    "            \"Test PR-AUC\": pr_auc,\n",
    "            \"Best Parameters\": best_params,\n",
    "            \"hyperparameter_importance\": importance,\n",
    "            \"confusion_matrix\": conf_matrix\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9uUCw7NbcWdv",
    "outputId": "155f35c6-a516-40b0-9588-5ff978ae0725"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(combined_results)\n",
    "\n",
    "results_df.to_csv(\"mlp_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
